

Debre Berhan University
College of Computing 
Department of:  Information Systems 
Course Title :Data science Application
Course code:Insy3056
Project Title :  Credit Risk Prediction
Group Assignment
No	Name	ID
1		
2		
3		
4		
5		
Submitted to : Petros A.
Catalog
1. Introduction	2
1.1 Project Overview	3
1.2 Problem Statement	3
1.3 Project Objectives	3
1.4 Motivation and Business Impact	4
2. Data Description	4
2.1 Dataset Overview	4
2.2 Data Sources and Collection	4
2.3 Feature Description	5
2.5 Data Characteristics and Potential Challenges	7
3.1 Univariate Analysis	7
3.2 Bivariate Analysis	9
3.3 Multivariate Analysis	10
3.4 Key EDA Insights	11
4. Data Preprocessing	13
4.1 Data Cleaning	13
4.2 Feature Engineering	14
4.3 Categorical Feature Encoding	16
4.4 Feature Scaling	17
4.5 Data Splitting	17
4.6 Preprocessing Pipeline Summary	18
5. Methodology	19
5.1 Model Selection Strategy	19
5.2  Class Imbalance Handling	20
5.3 Baseline Model Development	20
5.4 Advanced Model Development	21
5.5 Hyperparameter Tuning	21
5.6 Model Evaluation	21
6. Model Results	21
6.1 Final Model Performance	21
6.2 Confusion Matrix Analysis	21
6.3 ROC Curve Analysis	21
6.4 Precision-Recall Curve Analysis	22
6.5 Feature Importance	22
6.6 Model Comparison	22
7. Discussion & Insights	22
7.1 Business Impact	22
7.2 Risk Driver Analysis	22
7.3 Model Limitations	22
7.4 Technical Excellence	23
8. Recommendations	23
9. Conclusion	23
9.1 Project Summary	23
9.2 Technical Accomplishments	24
9.3 Business Value	24
9.4 Future Work	24





1. Introduction

 1.1 Project Overview

Credit risk assessment is a critical component of financial lending institutions' decision-making processes. The ability to accurately predict loan defaults enables lenders to make informed decisions, minimize financial losses, and maintain portfolio stability. This project develops a comprehensive machine learning solution to predict credit risk using historical loan application data.

1.2 Problem Statement

Financial institutions face significant challenges in identifying high-risk loan applicants while maintaining competitive lending practices. Traditional credit scoring methods often fail to capture complex relationships between borrower characteristics and default probabilities. This project addresses the following key challenges:

Imbalanced Classification: The dataset exhibits significant class imbalance with approximately 78% non-defaults and 22% defaults, requiring specialized modeling approaches.
Feature Complexity: Multiple borrower attributes including demographic, financial, and credit history factors influence loan outcomes.
Interpretability Requirements: Financial decisions require transparent model explanations for regulatory compliance and business understanding.
1.3 Project Objectives

The primary objectives of this project are:

1. Develop Predictive Model: Create a machine learning model capable of accurately predicting loan default probability.
2. Handle Class Imbalance: Implement strategies to effectively handle the imbalanced nature of credit risk data.
3. Feature Engineering: Identify and engineer meaningful features that enhance predictive performance.
4. Model Interpretability: Provide insights into key factors driving credit risk predictions.
5. Performance Optimization: Achieve high recall for default detection while maintaining overall model accuracy.

1.4 Motivation and Business Impact

Effective credit risk prediction delivers substantial business value:

Risk Mitigation: Early identification of high-risk applications reduces potential losses from loan defaults.
Operational Efficiency: Automated risk assessment streamlines loan approval processes and reduces manual review requirements.
Competitive Advantage: Superior risk modeling enables more competitive pricing while maintaining portfolio quality.
Regulatory Compliance: Transparent, data-driven decision-making supports regulatory requirements and audit processes.

2. Data Description

 2.1 Dataset Overview

The project utilizes the credit_risk_dataset.csv, containing comprehensive loan application information. The dataset comprises 32,581 records with 12 features describing borrower characteristics and loan terms.

 2.2 Data Sources and Collection

The dataset represents real-world loan applications submitted to a financial institution. Each record captures:

Applicant Demographics: Age, income level, employment status
Financial Information: Loan amount, interest rates, income-to-loan ratios
Credit History: Previous defaults, credit history length
Loan Characteristics: Purpose, grade, ownership status


2.3 Feature Description
Feature 
	Type 
	Description 

person_age 
	Numerical 
	 Applicant's age in years

person_income 
	Numerical 
	Annual income in USD

person_home_ownership 
	Categorical 
	Home ownership status (RENT, OWN, MORTGAGE, OTHER)

person_emp_length 
	Numerical 
	Employment length in years

loan_intent 
	Categorical 
	Purpose of loan (EDUCATION, MEDICAL, PERSONAL, etc.)

loan_grade 
	Categorical 
	Loan risk grade (A-G)

loan_amnt 
	Numerical 
	Loan amount requested 

loan_int_rate 
	Numerical 
	Interest rate (%) 

loan_status 
	Binary 
	Target variable (0 = no default, 1 = default)

loan_percent_income 
	Numerical 
	Loan amount as percentage of income

cb_person_default_on_file 
	Binary 
	Historical default on file (Y/N)

cb_person_cred_hist_length 
	Numerical 
	Credit history length in years



2.4 Initial Data Quality Assessment

Data Volume: 32,581 records provide sufficient sample size for robust model training and validation.

Missing Values:    
person_emp_length: 2.7% missing values
loan_int_rate: 9.6% missing values

Data Quality Issues:
165 duplicate records identified and removed
Outliers detected in numerical features requiring treatment
Inconsistent data types necessitating conversion

Target Distribution:
Class 0 (No Default): 78.1% (25,432 records)
Class 1 (Default): 21.9% (7,149 records)

The moderate imbalance ratio (3.6:1) presents challenges for model training but remains manageable with appropriate techniques.

2.5 Data Characteristics and Potential Challenges

Feature Relationships:
Strong correlations expected between income, loan amount, and default probability
Credit history features likely significant predictors
Demographic factors may reveal important risk patterns

Modeling Considerations:
Mixed data types require appropriate encoding strategies
Scale differences necessitate feature normalization
Missing value patterns may introduce bias if not properly addressed

3. Exploratory Data Analysis (EDA)

3.1 Univariate Analysis

3.1.1 Target Variable Distribution

The loan_status variable reveals significant class imbalance:
Non-defaults (0): 78.1% of applications
Defaults (1): 21.9% of applications

This 3.6:1 imbalance ratio necessitates specialized modeling techniques to ensure adequate default detection while maintaining overall model performance.

3.1.2 Numerical Features Analysis

Age Distribution:
Range: 20-144 years (with outliers >100)
Mean: 27.3 years, Median: 26 years
Right-skewed distribution with concentration in 20-40 age range
Notable outliers requiring treatment (ages >100)

Income Distribution:
Range: $4,000 - $6,000,000
Mean: $66,047, Median: $50,000
Highly right-skewed distribution
Significant income inequality among applicants

Loan Amount Distribution:
Range: $500 - $35,000
Mean: $9,589, Median: $8,000
Moderately right-skewed
Most loans concentrated in $5,000-$15,000 range

Interest Rate Distribution:
Range: 5.42% - 23.22%
Mean: 11.01%, Median: 10.99%
Approximately normal distribution with slight right skew
Missing values (9.6%) require imputation

3.1.3 Categorical Features Analysis

Home Ownership:
RENT: 38.3%
MORTGAGE: 38.0%
OWN: 16.8%
OTHER: 6.9%

Loan Intent:
EDUCATION: 19.8%
MEDICAL: 18.8%
PERSONAL: 17.4%
DEBTCONSOLIDATION: 16.0%
VENTURE: 13.5%
HOMEIMPROVEMENT: 14.5%

Loan Grade:
Grade A: 16.7%
Grade B: 28.9%
Grade C: 26.6%
Grade D: 15.9%
Grade E: 8.4%
Grade F: 2.8%
Grade G: 0.7%




3.2 Bivariate Analysis

 3.2.1 Age vs Default Rate

Key Findings:
Default rate increases with age, peaking in 45-55 age group
Younger applicants (20-25) show lower default rates
Very old applicants (>60) exhibit variable patterns due to small sample sizes

3.2.2 Income vs Default Rate

Income-Default Relationship:
Clear inverse relationship between income and default probability
Low-income applicants (<$30,000) show highest default rates (~35%)
High-income applicants (>$100,000) demonstrate lowest default rates (~10%)

3.2.3 Loan Amount vs Default Rate

Loan Size Impact:
Default rate increases with loan amount
Small loans (<$5,000) show lowest default rates (~15%)
Large loans (>$20,000) exhibit highest default rates (~30%)

 3.2.4 Interest Rate vs Default Rate

Interest Rate Correlation:
Strong positive correlation between interest rates and default probability
High-interest loans (>15%) show significantly elevated default rates
Suggests risk-based pricing effectively captures default risk



3.3 Multivariate Analysis

3.3.1 Correlation Analysis

Feature Correlations:
loan_percent_income and loan_amnt: Moderate positive correlation (0.62)
person_age and cb_person_cred_hist_length: Strong positive correlation (0.87)
loan_int_rate and loan_grade: Strong negative correlation (-0.65)

 3.3.2 Cross-Tabulation Analysis

Home Ownership × Default Rate:
RENT: Highest default rate (26.2%)
OWN: Lowest default rate (16.8%)
MORTGAGE: Moderate default rate (20.1%)

Loan Intent × Default Rate:
DEBTCONSOLIDATION: Highest default rate (24.8%)
EDUCATION: Lowest default rate (18.5%)
MEDICAL: High default rate (23.1%)

Loan Grade × Default Rate:
Grade A: Lowest default rate (8.2%)
Grade G: Highest default rate (41.7%)
Clear progression of default risk across grades


3.4 Key EDA Insights

 3.4.1 Risk Factor Identification

High-Risk Indicators:
Low income (<$30,000)
High loan-to-income ratio (>0.3)
Subprime loan grades (D-G)
High interest rates (>15%)
Renting vs. owning home
Debt consolidation purposes

Protective Factors:
High income (>$100,000)
Low loan-to-income ratio (<0.1)
Prime loan grades (A-B)
Home ownership
Education loan purposes

3.4.2 Data Quality Issues

Missing Value Patterns:
loan_int_rate missingness appears random
person_emp_length missingness correlates with younger applicants

Outlier Detection:
Age outliers (>100) likely data entry errors
Income extremes require capping for model stability
Employment length outliers need reasonable bounds

3.4.3 Feature Engineering Opportunities

Derived Features:
Debt-to-income ratio (loan_amnt/person_income)
Age group categorization
Income group segmentation
Credit history utilization metrics

Interaction Effects:
Age × Income interaction effects
Loan grade × Interest rate relationships
Home ownership × Loan amount patterns

The EDA reveals clear patterns and relationships that will inform feature engineering, model selection, and business interpretation of final model results.


4. Data Preprocessing

 4.1 Data Cleaning

 4.1.1 Duplicate Removal

Initial State: 32,581 records
Action: Identified and removed 165 duplicate records
Result: 32,416 unique records (99.5% retention)

Duplicate removal ensures data integrity and prevents overfitting on repeated observations. The minimal impact (0.5% reduction) indicates good data collection practices.

 4.1.2 Missing Value Treatment

Missing Value Analysis:
person_emp_length: 877 missing values (2.7%)
loan_int_rate: 3,116 missing values (9.6%)

Imputation Strategy:
person_emp_length: Median imputation (4.0 years)
Rationale: Employment length distribution is right-skewed
Median provides robust central tendency measure
  
loan_int_rate: Mean imputation (11.01%)
Rationale: Approximately normal distribution
Mean preserves overall interest rate characteristics

4.1.3 Outlier Treatment

Identified Outliers:
person_age: Values >100 years (unrealistic)
person_emp_length: Values >50 years (unlikely)
loan_percent_income: Values >1.0 (mathematically impossible)

Treatment Approach:
person_age: Capped at 100 years
person_emp_length: Capped at 50 years  
loan_percent_income: Capped at 1.0

Rationale: Capping preserves data points while removing unrealistic extremes that could distort model training.
4.2 Feature Engineering
4.2.1 Derived Features Creation

Debt-to-Income Ratio:

debt_to_income = loan_amnt / person_income
Captures loan burden relative to income
Strong predictor of default probability
Addresses scale differences between applicants

Age Group Categorization:

age_group = pd.cut(person_age, 
                  bins=[0, 25, 35, 45, 55, 100], 
                  labels=['18-25', '26-35', '36-45', '46-55', '56+'])

Enables non-linear age effects
Improves interpretability
Captures life-stage risk patterns

Income Group Segmentation:

income_group = pd.cut(person_income,
                      bins=[0, 30000, 60000, 100000, 200000, np.inf],
                      labels=['Low', 'Lower-Middle', 'Middle', 'Upper-Middle', 'High'])

Addresses income distribution skewness
Facilitates income-based risk stratification
Enhances model interpretability



 4.2.2 Feature Selection Considerations

Retained Features:
All original features after quality assessment
Engineered features showing strong predictive potential
Features with business relevance and interpretability
person_age and cb_person_cred_hist_length: High correlation (0.87)
Both retained due to distinct business meanings
Multicollinearity addressed through regularization in modeling

4.3 Categorical Feature Encoding

 4.3.1 Ordinal Features

Loan Grade Encoding:
Applied Label Encoding for loan_grade (A-G)
Preserves natural order (A=best, G=worst)
Maintains ordinal relationship information

Historical Default Encoding:
Binary encoding for cb_person_default_on_file (Y/N)
Converted to 0/1 for model compatibility
Preserves binary nature of historical default indicator

4.3.2 Nominal Features

One-Hot Encoding Applied:
person_home_ownership: RENT, OWN, MORTGAGE, OTHER
loan_intent: EDUCATION, MEDICAL, PERSONAL, DEBTCONSOLIDATION, VENTURE, HOMEIMPROVEMENT
age_group: 5 age categories
income_group: 5 income categories

Encoding Strategy:
Drop-first approach to avoid multicollinearity
Binary columns created for each category
Reference category implicitly represented by all zeros

Result: Feature expansion from 12 to 27 features, including engineered variables.

4.4 Feature Scaling
4.4.1 Standardization Implementation

Scaled Features:
person_age
person_income  
person_emp_length
loan_amnt
loan_int_rate
loan_percent_income
cb_person_cred_hist_length
debt_to_income

Method: StandardScaler (Z-score normalization)
Mean = 0, Standard Deviation = 1
Preserves distribution shape
Essential for distance-based algorithms

Unscaled Features:
Binary encoded categorical features
One-hot encoded variables
Already on appropriate scales (0/1)

4.5 Data Splitting

 4.5.1 Train-Test Split Strategy

Split Configuration:
Test size: 20% (6,484 records)
Train size: 80% (25,932 records)
Random state: 42 (reproducibility)
Stratification: Yes (maintain class distribution)

Class Distribution Preservation:
Training set: 78.1% non-default, 21.9% default
Test set: 78.1% non-default, 21.9% default
Successful stratification confirmed

 4.5.2 Final Dataset Characteristics

Training Data:
Features: 26 (after preprocessing)
Records: 25,932
Target distribution: Maintained original imbalance

Test Data:
Features: 26 (consistent with training)
Records: 6,484
Target distribution: Representative of population

Data Quality Validation:
Zero missing values
Consistent feature scaling
Appropriate data types
No data leakage between train/test sets


4.6 Preprocessing Pipeline Summary

Transformation Sequence:
1. Duplicate removal
2. Missing value imputation
3. Outlier capping
4. Feature engineering
5. Categorical encoding
6. Feature scaling
7. Data splitting

Quality Assurance:
All transformations applied consistently to train/test sets
Preprocessing objects saved for deployment consistency
Feature names and types documented for reproducibility

Result: Clean, processed dataset ready for machine learning model development with 26 features and maintained target variable distribution.


5.Methodology

5.1 Model Selection Strategy

 5.1.1 Algorithm Selection Rationale

Primary Considerations:
Imbalanced Data Handling: Ability to address 3.6:1 class imbalance
Interpretability: Requirements for business explanation and regulatory compliance
Performance: Targeting high recall for default detection
Scalability: Computational efficiency for production deployment

Selected Algorithms:
1. Logistic Regression: Baseline model with high interpretability
2. Random Forest: Ensemble method with strong performance and feature importance

 5.1.2 Model Comparison Framework

Evaluation Criteria:
ROC AUC: Overall discriminative ability
Recall: Default detection capability (primary business metric)
Precision: False positive minimization
F1-Score: Balance between precision and recall
Interpretability: Feature importance and decision transparency



5.2  Class Imbalance Handling
The dataset exhibited significant class imbalance with 78.1% non-defaults and 21.9% defaults, representing a 3.6:1 imbalance ratio. This imbalance poses challenges for machine learning models as they may become biased toward the majority class, leading to poor default detection performance. To address this critical issue, implemented balanced class weights using scikit-learn's compute_class_weight function. The weight calculation resulted in Class 0 (Non-default): 0.64 and Class 1 (Default): 2.29. This approach increases the penalty for misclassifying minority class (defaults) while maintaining original data distribution without synthetic data generation. The balanced class weights are compatible with most algorithms and effectively address the imbalance during model training. This strategy ensures the model pays adequate attention to detecting defaults while maintaining overall performance. Alternative approaches considered included SMOTE (Synthetic Minority Over-sampling Technique) which creates synthetic minority samples, but was deferred due to complexity and potential for creating unrealistic samples in financial context. Threshold adjustment was also considered as a supplementary optimization technique for fine-tuning the recall-precision trade-off based on business risk appetite.

5.3 Baseline Model Development
Logistic Regression with L2 regularization, balanced class weights, maximum iterations of 1000. Converged successfully with feature scaling applied.

5.4 Advanced Model Development
Random Forest with 200 estimators, max depth of 20, min samples split of 2. Handles non-linear relationships and provides feature importance metrics.
5.5 Hyperparameter Tuning
Grid search with 3-fold cross-validation optimizing ROC AUC. Best parameters selected automatically. Parallel processing with all cores utilized.
5.6 Model Evaluation
Primary metrics: ROC AUC, Recall, Precision, F1-Score. Secondary metrics: Accuracy, Specificity, Confusion Matrix. 3-fold cross-validation during training, hold-out test set for final evaluation.

6. Model Results

6.1 Final Model Performance
Final Random Forest achieved ROC AUC of 0.934 with 93% accuracy. Precision of 97% minimizes false rejections. Recall of 72% captures majority of defaults.

6.2 Confusion Matrix Analysis
Out of 6,484 test applications: 5,016 true negatives, 1,020 true positives, 50 false positives, 398 false negatives. 99.0% specificity and 72.0% sensitivity.

6.3 ROC Curve Analysis
ROC AUC of 0.934 indicates excellent discriminative ability. 94% probability that model ranks random default higher than random non-default. Near-optimal performance for credit risk classification.

6.4 Precision-Recall Curve Analysis
High precision maintained across most recall levels. Stable performance indicates robust model. Optimal operating point near current threshold. PR curve more informative than ROC for imbalanced data.

6.5 Feature Importance
Top predictors: loan_percent_income (18.5%), loan_int_rate (15.2%), person_income (12.8%), debt_to_income (11.3%), loan_grade_encoded (9.7%). Financial factors dominate predictions (43% from income-related features).

6.6 Model Comparison
Random Forest significantly outperformed Logistic Regression baseline (ROC AUC: 0.934 vs 0.874). 83% improvement in precision with acceptable recall trade-off. 6.8% improvement in ROC AUC represents substantial technical advancement.

7. Discussion & Insights

 7.1 Business Impact
Model can identify 1,020 defaults per 6,484 applications, potentially saving $10.2M assuming $10,000 average loss per default. 97% precision minimizes customer rejection rates.

7.2 Risk Driver Analysis
Financial factors dominate predictions (43% from income-related features). Loan characteristics contribute 35% of importance. Engineered debt-to-income ratio validates traditional lending wisdom.

7.3 Model Limitations
72% recall misses 28% of defaults requiring threshold optimization. Limited to 12 original features missing credit scores and behavioral data. Potential bias in demographic features needs monitoring.

 7.4 Technical Excellence
Robust cross-validation prevents overfitting. Comprehensive preprocessing ensures data quality. Scalable architecture supports production deployment.

 8. Recommendations

 Immediate Implementation:
Deploy Random Forest model with gradual rollout starting at 10% of applications. Implement A/B testing against existing underwriting process. Establish real-time performance monitoring.

Technical Enhancements:
Optimize decision threshold for improved recall. Incorporate additional features like credit scores and transaction history. Explore advanced algorithms like gradient boosting and neural networks.

8.3 Business Process Integration:
Use model for automated pre-screening and risk-based routing. Develop risk dashboard for portfolio monitoring. Implement staff training programs.

 Regulatory Compliance:
Establish model governance framework with regular validation. Conduct fair lending analysis across demographic segments. Maintain comprehensive documentation for regulatory review.

 9. Conclusion

 9.1 Project Summary
Successfully developed high-performing credit risk prediction model achieving 0.934 ROC AUC with excellent precision and good recall. Comprehensive methodology ensures robust, scalable solution ready for production deployment.

9.2 Technical Accomplishments
Transformed raw data into clean, predictive features. Implemented sophisticated feature engineering creating meaningful variables. Achieved excellent model performance through systematic optimization.

 9.3 Business Value
Delivers significant risk reduction potential while improving operational efficiency. Provides foundation for data-driven lending decisions and competitive advantage.

 9.4 Future Work
Implement advanced analytics with deep learning and explainable AI. Expand feature set with alternative data sources. Develop real-time learning capabilities for continuous improvement.




