{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddb851bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (32581, 12)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "data_path = '../data/raw/credit_risk_dataset.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Original shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e8d23",
   "metadata": {},
   "source": [
    "## Handle Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "307c6d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (32416, 12)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Shape after removing duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4d9755",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd34ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "person_emp_length     887\n",
      "loan_int_rate        3095\n",
      "dtype: int64\n",
      "Missing values after imputation:\n",
      "person_age                    0\n",
      "person_income                 0\n",
      "person_home_ownership         0\n",
      "person_emp_length             0\n",
      "loan_intent                   0\n",
      "loan_grade                    0\n",
      "loan_amnt                     0\n",
      "loan_int_rate                 0\n",
      "loan_status                   0\n",
      "loan_percent_income           0\n",
      "cb_person_default_on_file     0\n",
      "cb_person_cred_hist_length    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing = df.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "print(missing[missing > 0])\n",
    "\n",
    "# Impute person_emp_length with median\n",
    "df['person_emp_length'] = df['person_emp_length'].fillna(df['person_emp_length'].median())\n",
    "\n",
    "# Impute loan_int_rate with mean\n",
    "df['loan_int_rate'] = df['loan_int_rate'].fillna(df['loan_int_rate'].mean())\n",
    "\n",
    "print(\"Missing values after imputation:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001506a6",
   "metadata": {},
   "source": [
    "## Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7674d518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Before Outlier Treatment ===\n",
      "Original shape: (23695, 15)\n",
      "\n",
      "1. Removing invalid values...\n",
      "   Removed 0 records with age > 100\n",
      "   Removed 0 records with employment > working years\n",
      "   Removed 0 records with income > $500K\n",
      "\n",
      "2. Applying log transformation to income...\n",
      "\n",
      "3. Applying capping...\n",
      "   Winsorized loan_amnt\n",
      "   Winsorized loan_int_rate\n",
      "   Winsorized loan_percent_income\n",
      "\n",
      "4. Creating robust features...\n",
      "\n",
      "=== After Outlier Treatment ===\n",
      "Final shape: (23695, 15)\n",
      "Records removed: 8721 (26.9%)\n",
      "\n",
      "=== Summary Statistics After Treatment ===\n",
      "         person_age  person_income  person_emp_length     loan_amnt\n",
      "count  23695.000000   23695.000000       23695.000000  23695.000000\n",
      "mean      28.675839   63781.511247           3.468495   9422.978476\n",
      "std        6.604860   41331.271286           3.295614   6053.441181\n",
      "min       20.000000    4000.000000           0.000000   1200.000000\n",
      "25%       24.000000   37200.000000           1.000000   5000.000000\n",
      "50%       27.000000   54000.000000           3.000000   8000.000000\n",
      "75%       32.000000   78000.000000           5.000000  12000.000000\n",
      "max       94.000000  500000.000000          41.000000  28000.000000\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Outlier Treatment\n",
    "print(\"=== Before Outlier Treatment ===\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "\n",
    "# 1. Remove invalid/impossible values\n",
    "print(\"\\n1. Removing invalid values...\")\n",
    "# Remove impossible ages (> 80)\n",
    "age_outliers = df[df['person_age'] > 100].shape[0]\n",
    "df = df[df['person_age'] <= 100]\n",
    "print(f\"   Removed {age_outliers} records with age > 100\")\n",
    "\n",
    "# Remove impossible employment length (can't exceed working years)\n",
    "emp_outliers = df[df['person_emp_length'] > (df['person_age'] - 18)].shape[0]\n",
    "df = df[df['person_emp_length'] <= (df['person_age'] - 18)]\n",
    "print(f\"   Removed {emp_outliers} records with employment > working years\")\n",
    "\n",
    "# Remove extreme income values (> $500K)\n",
    "income_outliers = df[df['person_income'] > 500000].shape[0]\n",
    "df = df[df['person_income'] <= 500000]\n",
    "print(f\"   Removed {income_outliers} records with income > $500K\")\n",
    "\n",
    "# 2. Log transformation for skewed income data\n",
    "print(\"\\n2. Applying log transformation to income...\")\n",
    "df['person_income_log'] = np.log1p(df['person_income'])\n",
    "\n",
    "# 3. Winsorization for remaining outliers\n",
    "print(\"\\n3. Applying capping...\")\n",
    "def winsorize_column(df, column, lower=0.01, upper=0.99):\n",
    "    lower_bound = df[column].quantile(lower)\n",
    "    upper_bound = df[column].quantile(upper)\n",
    "    df[column] = df[column].clip(lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "# Apply winsorization to key numerical columns\n",
    "cols_to_winsorize = ['loan_amnt', 'loan_int_rate', 'loan_percent_income']\n",
    "for col in cols_to_winsorize:\n",
    "    df = winsorize_column(df, col)\n",
    "    print(f\"   Winsorized {col}\")\n",
    "\n",
    "# 4. Create robust features\n",
    "print(\"\\n4. Creating robust features...\")\n",
    "# Income per year of age\n",
    "df['income_per_age'] = df['person_income'] / df['person_age']\n",
    "\n",
    "# Loan to income ratio (already exists as loan_percent_income)\n",
    "# Employment stability score\n",
    "df['emp_stability'] = np.where(df['person_emp_length'] >= 5, 1, 0)\n",
    "\n",
    "print(f\"\\n=== After Outlier Treatment ===\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"Records removed: {32416 - df.shape[0]} ({((32416 - df.shape[0])/32416)*100:.1f}%)\")\n",
    "\n",
    "# Show summary statistics after treatment\n",
    "print(\"\\n=== Summary Statistics After Treatment ===\")\n",
    "print(df[['person_age', 'person_income', 'person_emp_length', 'loan_amnt']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3879b",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "177d5193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features created.\n"
     ]
    }
   ],
   "source": [
    "# Create debt-to-income ratio\n",
    "df['debt_to_income'] = df['loan_amnt'] / df['person_income']\n",
    "\n",
    "# Create age groups\n",
    "df['age_group'] = pd.cut(df['person_age'], bins=[0, 25, 35, 45, 55, 100], labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "\n",
    "# Create income groups\n",
    "df['income_group'] = pd.cut(df['person_income'], bins=[0, 30000, 60000, 100000, 200000, np.inf], labels=['Low', 'Lower-Middle', 'Middle', 'Upper-Middle', 'High'])\n",
    "\n",
    "print(\"New features created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217eabb",
   "metadata": {},
   "source": [
    "## Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17f654ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features encoded.\n",
      "Shape after encoding: (24530, 30)\n"
     ]
    }
   ],
   "source": [
    "# Label encode ordinal features\n",
    "le_loan_grade = LabelEncoder()\n",
    "df['loan_grade_encoded'] = le_loan_grade.fit_transform(df['loan_grade'])\n",
    "\n",
    "le_default = LabelEncoder()\n",
    "df['cb_person_default_on_file_encoded'] = le_default.fit_transform(df['cb_person_default_on_file'])\n",
    "\n",
    "# One-hot encode nominal features\n",
    "categorical_cols = ['person_home_ownership', 'loan_intent', 'age_group', 'income_group']\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Drop original string columns that were encoded\n",
    "df_encoded = df_encoded.drop(['loan_grade', 'cb_person_default_on_file'], axis=1)\n",
    "\n",
    "print(\"Categorical features encoded.\")\n",
    "print(f\"Shape after encoding: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f90d94",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17731003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature Scaling ===\n",
      "Features to scale: 10\n",
      "Features: ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length', 'debt_to_income', 'person_income_log', 'income_per_age']\n",
      "✓ Numerical features scaled using RobustScaler\n",
      "✓ RobustScaler uses median and IQR (less sensitive to outliers)\n",
      "\n",
      "=== Scaling Statistics ===\n",
      "      person_age  person_income  person_emp_length  loan_amnt  loan_int_rate  \\\n",
      "mean    0.204612       0.224700           0.121698   0.191680       0.012899   \n",
      "std     0.820104       1.014580           0.810105   0.863171       0.655118   \n",
      "min    -0.875000      -1.231436          -0.750000  -1.000000      -1.208913   \n",
      "max     6.625000      10.984410           9.500000   2.857143       1.592383   \n",
      "\n",
      "      loan_percent_income  cb_person_cred_hist_length  debt_to_income  \\\n",
      "mean             0.152638                    0.222381        0.155892   \n",
      "std              0.749403                    0.716012        0.762626   \n",
      "min             -0.928571                   -0.500000       -1.036767   \n",
      "max              2.500000                    4.166667        4.862079   \n",
      "\n",
      "      person_income_log  income_per_age  \n",
      "mean          -0.010266        0.223256  \n",
      "std            0.757050        0.956021  \n",
      "min           -3.473165       -1.231480  \n",
      "max            2.970231       11.124223  \n"
     ]
    }
   ],
   "source": [
    "# Robust Feature Scaling\n",
    "print(\"=== Feature Scaling ===\")\n",
    "\n",
    "# Select numerical features to scale\n",
    "numerical_cols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', \n",
    "                  'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length', \n",
    "                  'debt_to_income', 'person_income_log', 'income_per_age']\n",
    "\n",
    "print(f\"Features to scale: {len(numerical_cols)}\")\n",
    "print(f\"Features: {numerical_cols}\")\n",
    "\n",
    "# Use RobustScaler for better outlier handling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform numerical features\n",
    "df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])\n",
    "\n",
    "print(\"✓ Numerical features scaled using RobustScaler\")\n",
    "print(\"✓ RobustScaler uses median and IQR (less sensitive to outliers)\")\n",
    "\n",
    "# Show scaling statistics\n",
    "print(\"\\n=== Scaling Statistics ===\")\n",
    "scaled_stats = df_encoded[numerical_cols].describe()\n",
    "print(scaled_stats.loc[['mean', 'std', 'min', 'max']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fabead3",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b85a02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (19624, 29), Test shape: (4906, 29)\n",
      "Train target distribution: loan_status\n",
      "0    0.770791\n",
      "1    0.229209\n",
      "Name: proportion, dtype: float64\n",
      "Test target distribution: loan_status\n",
      "0    0.770689\n",
      "1    0.229311\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df_encoded.drop('loan_status', axis=1)\n",
    "y = df_encoded['loan_status']\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(f\"Train target distribution: {y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Test target distribution: {y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baa9db17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acce9e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Summary ===\n",
      "Original data: 32,416 records\n",
      "After outlier removal: 24,530 records\n",
      "After preprocessing: (24530, 30)\n",
      "Training set: (19624, 29)\n",
      "Test set: (4906, 29)\n",
      "\n",
      "=== Outlier Treatment Summary ===\n",
      "Records removed: 7,886 (24.3%)\n",
      "   - Age > 80 years\n",
      "   - Employment > working years\n",
      "   - Income > $500K\n",
      "   - Applied log transformation to income\n",
      "   - Applied winsorization to loan features\n",
      "\n",
      "=== Class Distribution ===\n",
      "Training set:\n",
      "  Class 0 (No Default): 15,126 (77.1%)\n",
      "  Class 1 (Default): 4,498 (22.9%)\n",
      "Test set:\n",
      "  Class 0 (No Default): 3,781 (77.1%)\n",
      "  Class 1 (Default): 1,125 (22.9%)\n",
      "\n",
      "=== Data Quality ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 0\n",
      "Features: 29\n",
      "Scaling method: RobustScaler (median & IQR)\n",
      "✓ Data ready for modeling\n"
     ]
    }
   ],
   "source": [
    "## Data Summary\n",
    "\n",
    "print(\"=== Dataset Summary ===\")\n",
    "print(f\"Original data: {32416:,} records\")\n",
    "print(f\"After outlier removal: {df.shape[0]:,} records\")\n",
    "print(f\"After preprocessing: {df_encoded.shape}\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "print(f\"\\n=== Outlier Treatment Summary ===\")\n",
    "print(f\"Records removed: {32416 - df.shape[0]:,} ({((32416 - df.shape[0])/32416)*100:.1f}%)\")\n",
    "print(\"   - Age > 80 years\")\n",
    "print(\"   - Employment > working years\")\n",
    "print(\"   - Income > $500K\")\n",
    "print(\"   - Applied log transformation to income\")\n",
    "print(\"   - Applied winsorization to loan features\")\n",
    "\n",
    "print(f\"\\n=== Class Distribution ===\")\n",
    "print(\"Training set:\")\n",
    "print(f\"  Class 0 (No Default): {y_train.value_counts()[0]:,} ({y_train.value_counts(normalize=True)[0]:.1%})\")\n",
    "print(f\"  Class 1 (Default): {y_train.value_counts()[1]:,} ({y_train.value_counts(normalize=True)[1]:.1%})\")\n",
    "print(\"Test set:\")\n",
    "print(f\"  Class 0 (No Default): {y_test.value_counts()[0]:,} ({y_test.value_counts(normalize=True)[0]:.1%})\")\n",
    "print(f\"  Class 1 (Default): {y_test.value_counts()[1]:,} ({y_test.value_counts(normalize=True)[1]:.1%})\")\n",
    "\n",
    "print(f\"\\n=== Data Quality ===\")\n",
    "print(f\"Missing values: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Scaling method: RobustScaler (median & IQR)\")\n",
    "print(\"✓ Data ready for modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c984bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Saved Successfully ===\n",
      "✓ Training data: (19624, 29)\n",
      "✓ Test data: (4906, 29)\n",
      "✓ RobustScaler saved\n",
      "✓ Label encoders saved\n",
      "✓ Outlier treatment parameters saved\n",
      "✓ Ready for model training\n"
     ]
    }
   ],
   "source": [
    "## Save Processed Data\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save training and test data\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv')\n",
    "\n",
    "# Save preprocessing objects\n",
    "joblib.dump(scaler, '../models/robust_scaler.pkl')\n",
    "joblib.dump(le_loan_grade, '../models/le_loan_grade.pkl')\n",
    "joblib.dump(le_default, '../models/le_default.pkl')\n",
    "\n",
    "# Save outlier treatment parameters\n",
    "outlier_params = {\n",
    "    'max_age': 80,\n",
    "    'max_income': 500000,\n",
    "    'winsorize_bounds': (0.01, 0.99),\n",
    "    'log_transform_income': True\n",
    "}\n",
    "joblib.dump(outlier_params, '../models/outlier_params.pkl')\n",
    "\n",
    "print(\"=== Data Saved Successfully ===\")\n",
    "print(f\"✓ Training data: {X_train.shape}\")\n",
    "print(f\"✓ Test data: {X_test.shape}\")\n",
    "print(f\"✓ RobustScaler saved\")\n",
    "print(f\"✓ Label encoders saved\")\n",
    "print(f\"✓ Outlier treatment parameters saved\")\n",
    "print(f\"✓ Ready for model training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
